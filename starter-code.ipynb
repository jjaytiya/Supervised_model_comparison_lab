{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Supervised Learning Model Comparison\n",
    "\n",
    "---\n",
    "\n",
    "### Let us begin...\n",
    "\n",
    "Recall the `data science process`.\n",
    "   1. Define the problem.\n",
    "   2. Gather the data.\n",
    "   3. Explore the data.\n",
    "   4. Model the data.\n",
    "   5. Evaluate the model.\n",
    "   6. Answer the problem.\n",
    "\n",
    "In this lab, we're going to focus mostly on creating (and then comparing) many regression and classification models. Thus, we'll define the problem and gather the data for you.\n",
    "Most of the questions requiring a written response can be written in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the problem.\n",
    "\n",
    "You are a data scientist with a financial services company. Specifically, you want to leverage data in order to identify potential customers.\n",
    "\n",
    "If you are unfamiliar with \"401(k)s\" or \"IRAs,\" these are two types of retirement accounts. Very broadly speaking:\n",
    "- You can put money for retirement into both of these accounts.\n",
    "- The money in these accounts gets invested and hopefully has a lot more money in it when you retire.\n",
    "- These are a little different from regular bank accounts in that there are certain tax benefits to these accounts. Also, employers frequently match money that you put into a 401k.\n",
    "- If you want to learn more about them, check out [this site](https://www.nerdwallet.com/article/ira-vs-401k-retirement-accounts).\n",
    "\n",
    "We will tackle one regression problem and one classification problem today.\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k.\n",
    "\n",
    "Check out the data dictionary [here](http://fmwww.bc.edu/ec-p/data/wooldridge2k/401KSUBS.DES).\n",
    "\n",
    "#### NOTE: When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable. \n",
    "\n",
    "#### When predicting `e401k`, you may use the entire dataframe if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier, RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Gather the data.\n",
    "\n",
    "##### 1. Read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./401ksubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['e401k', 'inc', 'marr', 'male', 'age', 'fsize', 'nettfa', 'p401k',\n",
       "       'pira', 'incsq', 'agesq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. What are 2-3 other variables that, if available, would be helpful to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Highest education > as this may reflect to income\n",
    "# 2. Credit score > shows the financial behavior of the participant in this data \n",
    "# 3. Debt > if the participant have high debt, they might not enroll in 401K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Suppose a peer recommended putting `race` into your model in order to better predict who to target when advertising IRAs and 401(k)s. Why would this be an unethical decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's unethical decision. putting race is violate the privacy and not a good practice for ethical standards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "##### 4. When attempting to predict income, which feature(s) would we reasonably not use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans\n",
    "# 'inc' , because we want to predict incomes. In this case will be my y (target variables)\n",
    "# 'incsq', for the same reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. What two variables have already been created for us through feature engineering? Come up with a hypothesis as to why subject-matter experts may have done this.\n",
    "> This need not be a \"statistical hypothesis.\" Just brainstorm why SMEs (Subject Matter Experts) might have done this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans\n",
    "# There are 2 variables in the dataset created though feature engineering.\n",
    "# 1. 'incsq' > income squared\n",
    "# 2. 'agesq' > age squared\n",
    "# The person who collect data may want to make and income be more robust to have the better prediction. \n",
    "# The squared terms will improve the model accuracy by letting it capture the curving patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Looking at the data dictionary, one variable description appears to be an error. What is this error, and what do you think the correct value would be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e401k</th>\n",
       "      <th>inc</th>\n",
       "      <th>marr</th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>fsize</th>\n",
       "      <th>nettfa</th>\n",
       "      <th>p401k</th>\n",
       "      <th>pira</th>\n",
       "      <th>incsq</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4.575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173.4489</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>61.230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>154.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3749.1130</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12.858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165.3282</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>98.880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21.800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9777.2540</td>\n",
       "      <td>1936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.614</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>18.450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>511.3930</td>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   e401k     inc  marr  male  age  fsize   nettfa  p401k  pira      incsq  \\\n",
       "0      0  13.170     0     0   40      1    4.575      0     1   173.4489   \n",
       "1      1  61.230     0     1   35      1  154.000      1     0  3749.1130   \n",
       "2      0  12.858     1     0   44      2    0.000      0     0   165.3282   \n",
       "3      0  98.880     1     1   44      2   21.800      0     0  9777.2540   \n",
       "4      0  22.614     0     0   53      1   18.450      0     0   511.3930   \n",
       "\n",
       "   agesq  \n",
       "0   1600  \n",
       "1   1225  \n",
       "2   1936  \n",
       "3   1936  \n",
       "4   2809  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually I see there are 2 variables that have error in description.\n",
    "\n",
    "# 1. 'inc : inc^2  can be described as 'income per person'\n",
    "    # Plus the value inside income is not telling the unit or the scale number that should be like in MB of in $1000\n",
    "\n",
    "# 2. 'age' : age^2 can be described as 'age of the participant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e401k     0.268178\n",
      "inc       1.000000\n",
      "marr      0.362008\n",
      "male     -0.069871\n",
      "age       0.105638\n",
      "fsize     0.110170\n",
      "nettfa    0.376586\n",
      "p401k     0.270833\n",
      "pira      0.364354\n",
      "incsq     0.940161\n",
      "agesq     0.087305\n",
      "Name: inc, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# I want to explore the correlation\n",
    "correlations = df.corr()\n",
    "print(correlations['inc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 1: Regression Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: What features best predict one's income?\n",
    "- When predicting `inc`, you should pretend as though you do not have access to the `e401k`, the `p401k` variable, and the `pira` variable.\n",
    "\n",
    "##### 7. List all modeling tactics we've learned that could be used to solve a regression problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific regression problem and explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear Regression – Yes: Can help to understand the relationships between each variables. \n",
    "# 2. Ridge Regression – Yes: This models help regularization for multicollinearity.\n",
    "# 3. Lasso Regression – Yes: This models help regularization with feature selection.\n",
    "# 4. XGBoost - Yes: This models help to understand the influence of the features.\n",
    "# 5. Random Forest Regression – No: Hard to interpret.\n",
    "# 6. KNN Regression – No: Hard to understand the incluence of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. Regardless of your answer to number 7, fit at least one of each of the following models to attempt to solve the regression problem above:\n",
    "    - a multiple linear regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend setting a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['e401k', 'inc', 'marr', 'male', 'age', 'fsize', 'nettfa', 'p401k',\n",
       "       'pira', 'incsq', 'agesq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Model  Mean Squared Error  Train R^2  Test R^2\n",
      "0         Linear Regression          458.058245   0.266254  0.239491\n",
      "1       K-Nearest Neighbors          414.573642   0.531082  0.311688\n",
      "2             Decision Tree          706.395105   0.987854 -0.172820\n",
      "3     Bagged Decision Trees          457.567714   0.862075  0.240305\n",
      "4             Random Forest          420.472157   0.892758  0.301895\n",
      "5                  AdaBoost          580.425115   0.080711  0.036326\n",
      "6  Support Vector Regressor          416.436236   0.323204  0.308595\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "# I want to use make_pipeline as it's shorthand that automatically assigns names to steps, useful for quick and simple pipelines.\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set up X,y\n",
    "X = df[['marr', 'agesq', 'fsize', 'nettfa']]  # Features\n",
    "y = df['inc']  # Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Define models in a dictionary to easily loop over them\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"K-Nearest Neighbors\": make_pipeline(StandardScaler(), KNeighborsRegressor()),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(random_state=RANDOM_SEED),\n",
    "    \"Bagged Decision Trees\": make_pipeline(StandardScaler(), BaggingRegressor(estimator=DecisionTreeRegressor(), random_state=RANDOM_SEED)),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=RANDOM_SEED),\n",
    "    \"AdaBoost\": AdaBoostRegressor(random_state=RANDOM_SEED),\n",
    "    \"Support Vector Regressor\": make_pipeline(StandardScaler(), svm.SVR())  \n",
    "    # Other models like Decision Trees, Random Forests, and AdaBoost don’t require scaling for the model itself.\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Fit each model and calculate MSE, Train R^2, and Test R^2\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Predict on test data\n",
    "    mse = mean_squared_error(y_test, y_pred)  # Calculate MSE\n",
    "    \n",
    "    # Train and test scores (R^2)\n",
    "    train_score = model.score(X_train, y_train)  # R^2 on training set\n",
    "    test_score = model.score(X_test, y_test)  # R^2 on test set\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Mean Squared Error': mse,\n",
    "        'Train R^2': train_score,\n",
    "        'Test R^2': test_score\n",
    "    })\n",
    "\n",
    "# Convert the results to DataFrame (I want easier for visualize the output)\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. What is bootstrapping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping is a method used to estimate the distribution of a sample by resampling with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10. What is the difference between a decision tree and a set of bagged decision trees? Be specific and precise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A decision tree is a single predictive model which splits data into branches based on feature values to make predictions.\n",
    "\n",
    "# A set of bagged decision trees trains multiple trees on different bootstrap samples and averages their predictions, \n",
    "# reducing overfitting and improving accuracy by lowering model variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 11. What is the difference between a set of bagged decision trees and a random forest? Be specific and precise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of bagged decision trees uses multiple trees trained on different bootstrap samples, averaging their predictions to reduce variance.\n",
    "\n",
    "# In a random forest, the process also begins with bootstrap sampling, \n",
    "# but with an added step at each node, only a random subset of features is considered for splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 12. Why might a random forest be superior to a set of bagged decision trees?\n",
    "> Hint: Consider the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests usually perform better than bagging because they reduce the correlation between the trees \n",
    "# as it a random feature selection therefore, Random Forests can reduce variance more effectively.\n",
    "\n",
    "# By reducing variance more, Random Forests often lead to a model that generalizes better to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 1: Regression Problem)\n",
    "\n",
    "##### 13. Using RMSE, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name : , Linear Regression\n",
      "Training RMSE: , 20.53593520213564\n",
      "Testing RMSE: , 21.402295330329196\n",
      "==================================\n",
      "Model name : , K-Nearest Neighbors\n",
      "Training RMSE: , 16.416859796590547\n",
      "Testing RMSE: , 20.361081542817715\n",
      "==================================\n",
      "Model name : , Decision Tree\n",
      "Training RMSE: , 2.642139911336674\n",
      "Testing RMSE: , 26.57809446479684\n",
      "==================================\n",
      "Model name : , Bagged Decision Trees\n",
      "Training RMSE: , 8.903542637985298\n",
      "Testing RMSE: , 21.39083248154066\n",
      "==================================\n",
      "Model name : , Random Forest\n",
      "Training RMSE: , 7.851000059550053\n",
      "Testing RMSE: , 20.50541774231338\n",
      "==================================\n",
      "Model name : , AdaBoost\n",
      "Training RMSE: , 22.986234492672242\n",
      "Testing RMSE: , 24.092013508724484\n",
      "==================================\n",
      "Model name : , Support Vector Regressor\n",
      "Training RMSE: , 19.72288789084942\n",
      "Testing RMSE: , 20.40676936181438\n",
      "==================================\n"
     ]
    }
   ],
   "source": [
    "def rmse(model, X_train, X_test, y_train, y_test):\n",
    "    # Calculate RMSE for train\n",
    "    mse_train = mean_squared_error(y_true = y_train,y_pred = model.predict(X_train))\n",
    "    \n",
    "    # Calculate RMSE for test\n",
    "    mse_test = mean_squared_error(y_true = y_test, y_pred = model.predict(X_test))\n",
    "    \n",
    "    rmse_train = np.sqrt(mse_train)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    print (f'Model name : , {name}')\n",
    "    print(f'Training RMSE: , {rmse_train}')\n",
    "    print(f'Testing RMSE: , {rmse_test}')\n",
    "    print('==================================')\n",
    "\n",
    "# Fit each model and evaluate RMSE\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    rmse(model, X_train, X_test, y_train, y_test)  # Calculate and print RMSE for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 14. Based on training RMSE and testing RMSE, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting is most likely occurring in:\n",
    "# - Decision Tree (low training RMSE, high testing RMSE)\n",
    "# - Bagged Decision Trees (lower training RMSE, higher testing RMSE)\n",
    "# - Random Forest (lower training RMSE, higher testing RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 15. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I would choose Linear Regression rather than other because...\n",
    "# - A slightly difference in RMSE between train and test\n",
    "# - Linear Regrssion is easy to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 16. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter: I didn't use GridSearchCV tuning my hyperparameter\n",
    "# Do the cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data. (Part 2: Classification Problem)\n",
    "\n",
    "Recall:\n",
    "- Problem: Predict whether or not one is eligible for a 401k.\n",
    "- When predicting `e401k`, you may use the entire dataframe if you wish.\n",
    "\n",
    "##### 17. While you're allowed to use every variable in your dataframe, mention at least one disadvantage of using `p401k` in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between e401k and p401k:, 0.7691696232534353\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation between e401k and p401k\n",
    "correlation = df['e401k'].corr(df['p401k'])\n",
    "print(f'Correlation between e401k and p401k:, {correlation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using p401k as a feature can cause data leakage, \n",
    "# as it's directly related to the target (e401k). \n",
    "\n",
    "#This can make the model's predictions too accurate and not generalizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 18. List all modeling tactics we've learned that could be used to solve a classification problem (as of Wednesday afternoon of Week 6). For each tactic, identify whether it is or is not appropriate for solving this specific classification problem and explain why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of these models below are appropriate for a classification problem \n",
    "# Logistic Regression Model : Great for simple binary classification.\n",
    "# K-nearest neighbors Model : Works well for smaller datasets but may struggle with large or high-dimensional data.\n",
    "# Decision Tree : Can easily overfit, but good for interpretable models.\n",
    "# Random Forests :A robust, powerful classifier that reduces overfitting.\n",
    "# Adaboost : Effective for complex, noisy problems and can boost weak models' performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 19. Regardless of your answer to number 18, fit at least one of each of the following models to attempt to solve the classification problem above:\n",
    "    - a logistic regression model\n",
    "    - a k-nearest neighbors model\n",
    "    - a decision tree\n",
    "    - a set of bagged decision trees\n",
    "    - a random forest\n",
    "    - an Adaboost model\n",
    "    \n",
    "> As always, be sure to do a train/test split! In order to compare modeling techniques, you should use the same train-test split on each. I recommend using a random seed here.\n",
    "\n",
    "> You may find it helpful to set up a pipeline to try each modeling technique, but you are not required to do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Model  Accuracy\n",
      "0    Logistic Regression  0.659838\n",
      "1    K-Nearest Neighbors  0.639353\n",
      "2          Decision Tree  0.585984\n",
      "3  Bagged Decision Trees  0.639353\n",
      "4          Random Forest  0.669003\n",
      "5               AdaBoost  0.686792\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Set up X,y \n",
    "X = df.drop(columns=['e401k', 'p401k'])\n",
    "y = df['e401k']# Target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "# Define models in a dictionary to easily loop over them\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_SEED,max_iter=10_000,solver='saga'),\n",
    "    \"K-Nearest Neighbors\": make_pipeline(StandardScaler(), KNeighborsClassifier()),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_SEED),\n",
    "    \"Bagged Decision Trees\": make_pipeline(StandardScaler(), BaggingClassifier(estimator=DecisionTreeClassifier(), random_state=RANDOM_SEED)),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_SEED),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME',random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Fit each model, predict, and calculate accuracy\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Train the model\n",
    "    y_pred = model.predict(X_test)  # Predict on test data\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy\n",
    "    \n",
    "    # Store the results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy\n",
    "    })\n",
    "\n",
    "# Convert the results to DataFrame for easier visualization\n",
    "results_update = pd.DataFrame(results)\n",
    "\n",
    "# Display the result\n",
    "print(results_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e401k\n",
      "0    0.607871\n",
      "1    0.392129\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate the model. (Part 2: Classfication Problem)\n",
    "\n",
    "##### 20. Suppose our \"positive\" class is that someone is eligible for a 401(k). What are our false positives? What are our false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positives : These are individuals who are predicted to be eligible for a 401(k) (positive class) but are actually not eligible. \n",
    "\n",
    "# False Negatives : These are individuals who are predicted to be not eligible for a 401(k) (negative class) but are actually eligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 21. In this specific case, would we rather minimize false positives or minimize false negatives? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize False Negatives BECAUSE....\n",
    "# If someone who is eligible misses out on a 401(k), \n",
    "# it can lead to legal and financial problems for the company and hurt employee satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 22. Suppose we wanted to optimize for the answer you provided in problem 21. Which metric would we optimize in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By optimizing for Recall.\n",
    "# TP / (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 23. Suppose that instead of optimizing for the metric in problem 21, we wanted to balance our false positives and false negatives using `f1-score`. Why might [f1-score](https://en.wikipedia.org/wiki/F1_score) be an appropriate metric to use here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F1-score is an appropriate metric to balance the importance of false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 24. Using f1-score, evaluate each of the models you fit on both the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Train F1-score: 0.3603\n",
      "Test F1-score: 0.3808\n",
      "===========================\n",
      "Model: K-Nearest Neighbors\n",
      "Train F1-score: 0.6515\n",
      "Test F1-score: 0.4966\n",
      "===========================\n",
      "Model: Decision Tree\n",
      "Train F1-score: 1.0000\n",
      "Test F1-score: 0.4674\n",
      "===========================\n",
      "Model: Bagged Decision Trees\n",
      "Train F1-score: 0.9705\n",
      "Test F1-score: 0.4858\n",
      "===========================\n",
      "Model: Random Forest\n",
      "Train F1-score: 1.0000\n",
      "Test F1-score: 0.5377\n",
      "===========================\n",
      "Model: AdaBoost\n",
      "Train F1-score: 0.5601\n",
      "Test F1-score: 0.5667\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Fit each model and calculate F1-score for Train and Test sets\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and testing sets\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for both training and testing data\n",
    "    f1_train = f1_score(y_train, y_train_pred)\n",
    "    f1_test = f1_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print the F1-score results for each model\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Train F1-score: {f1_train:.4f}\")\n",
    "    print(f\"Test F1-score: {f1_test:.4f}\")\n",
    "    print(\"===========================\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 25. Based on training f1-score and testing f1-score, is there evidence of overfitting in any of your models? Which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models showing clear overfitting are:\n",
    "# - Decision Tree\n",
    "# - Random Forest\n",
    "# These 2 models have a very high F1-score on the training data but much lower scores on the testing data, indicating overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 26. Based on everything we've covered so far, if you had to pick just one model as your final model to use to answer the problem in front of you, which one model would you pick? Defend your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on performance in terms of F1-scores, overfitting, and generalization, \n",
    "# I will choose AdaBoost as the final model. \n",
    "\n",
    "# Because...its balanced performance, good generalization to unseen data, and its robustness to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 27. Suppose you wanted to improve the performance of your final model. Brainstorm 2-3 things that, if you had more time, you would attempt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature Engineering \n",
    "# 2. Hyperparameter Tuning: adjust n_estimators, learning_rate\n",
    "# 3. Stratified sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Answer the problem.\n",
    "\n",
    "##### BONUS: Briefly summarize your answers to the regression and classification problems. Be sure to include any limitations or hesitations in your answer.\n",
    "\n",
    "- Regression: What features best predict one's income?\n",
    "- Classification: Predict whether or not one is eligible for a 401k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the regression problem, \n",
    "# Though the model performance suggests that some key variables are missing or need further refinement. \n",
    "# Models like Random Forest and K-Nearest Neighbors provide better predictions than simpler models like Linear Regression.\n",
    "\n",
    "\n",
    "# For the classification problem, \n",
    "# AdaBoost is the most accurate model for predicting 401k eligibility, \n",
    "# outperforming others such as Logistic Regression and Random Forest, \n",
    "# though improvements could still be made with further data preprocessing or fine-tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
